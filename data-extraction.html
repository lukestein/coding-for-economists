
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5. Extracting Data &#8212; Coding for Economists</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://aeturrell.github.io/coding-for-economists/data-extraction.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. Sharing Data" href="data-sharing.html" />
    <link rel="prev" title="4. Reading and Writing Files" href="data-read-and-write.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://aeturrell.github.io/coding-for-economists/data-extraction.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Extracting Data" />
<meta property="og:description" content="Extracting Data  Introduction  In this chapter, you’ll learn about some different ways to extract data: from the web, from documents, and elsewhere. This chapte" />
<meta property="og:image"       content="https://aeturrell.github.io/coding-for-economists/_static/smith_lovelace.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/smith_lovelace.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Coding for Economists</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Coding
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="code-preliminaries.html">
   1. Preliminaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="code-basics.html">
   2. Basics of Coding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="code-advanced.html">
   3. Advanced Coding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="code-where.html">
   4. Options for Writing Code
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Workflow
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="wrkflow-best-practice.html">
   1. Tips for Better Coding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wrkflow-advcd-best-practice.html">
   2. Tools for Better Coding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wrkflow-command-line.html">
   3. The Command Line
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="data-analysis-quickstart.html">
   1. Data Analysis Quickstart
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data-intro.html">
   2. Working with Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data-exploratory-analysis.html">
   3. Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data-read-and-write.html">
   4. Reading and Writing Files
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5. Extracting Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data-sharing.html">
   6. Sharing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data-advanced.html">
   7. Advanced Data
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data Visualisation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="vis-intro.html">
   1. Intro to Data Visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="vis-common-plots.html">
   2. Common Plots
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Econometrics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="econmt-probability-random.html">
   1. Probability and Random Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="econmt-statistics.html">
   2. Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="econmt-regression.html">
   3. Regression
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Analysis
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="text-intro.html">
   1. Introduction to Text
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Geospatial
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="geo-intro.html">
   1. Intro to Geo-Spatial Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="geo-vis.html">
   2. Geo-Spatial Visualisation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Mathematics with Code
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="maths-maths-coding.html">
   1. Intro to Mathematics with Code
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Coming from ...
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="coming-from-stata.html">
   Coming from Stata
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coming-from-matlab.html">
   Coming from Matlab
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coming-from-r.html">
   Coming from R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coming-from-excel.html">
   Coming from Excel
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Elsewhere
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   Bibliography
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/data-extraction.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/aeturrell/coding-for-economists"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/aeturrell/coding-for-economists/issues/new?title=Issue%20on%20page%20%2Fdata-extraction.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/aeturrell/coding-for-economists/main?urlpath=tree/data-extraction.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/aeturrell/coding-for-economists/blob/main/data-extraction.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   5.1. Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imports">
     5.1.1. Imports
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extracting-data-from-files-on-the-internet">
   5.2. Extracting data from files on the internet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extracting-data-using-apis">
   5.3. Extracting data using APIs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-easier-way-to-interact-with-some-apis">
     5.3.1. An easier way to interact with (some) APIs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#webscraping">
   5.4. Webscraping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extracting-data-from-pdfs">
   5.5. Extracting data from PDFs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extracting-images-and-text-from-pdfs">
     5.5.1. Extracting images and text from PDFs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tables">
     5.5.2. Tables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-useful-pdf-packages">
     5.5.3. Other useful PDF packages
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-extraction">
   5.6. Text extraction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#review">
   5.7. Review
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="extracting-data">
<h1><span class="section-number">5. </span>Extracting Data<a class="headerlink" href="#extracting-data" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2><span class="section-number">5.1. </span>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>In this chapter, you’ll learn about some different ways to extract data: from the web, from documents, and elsewhere. This chapter uses packages such as <strong>pandas-datareader</strong> and <strong>BeautifulSoup</strong> that you may need to install first.</p>
<div class="section" id="imports">
<h3><span class="section-number">5.1.1. </span>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h3>
<p>First we need to import the packages we’ll be using</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set max rows displayed for readability</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="c1"># Plot settings</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="extracting-data-from-files-on-the-internet">
<h2><span class="section-number">5.2. </span>Extracting data from files on the internet<a class="headerlink" href="#extracting-data-from-files-on-the-internet" title="Permalink to this headline">¶</a></h2>
<p>As you will have seen in some of the examples in this book, it’s easy to read data from the internet once you have the url and file type. Here, for instance, is an example that reads in the ‘storms’ dataset (we’ll only grab the first 10 rows):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv&#39;</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>name</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
      <th>lat</th>
      <th>long</th>
      <th>status</th>
      <th>category</th>
      <th>wind</th>
      <th>pressure</th>
      <th>ts_diameter</th>
      <th>hu_diameter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Amy</td>
      <td>1975</td>
      <td>6</td>
      <td>27</td>
      <td>0</td>
      <td>27.5</td>
      <td>-79.0</td>
      <td>tropical depression</td>
      <td>-1</td>
      <td>25</td>
      <td>1013</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Amy</td>
      <td>1975</td>
      <td>6</td>
      <td>27</td>
      <td>6</td>
      <td>28.5</td>
      <td>-79.0</td>
      <td>tropical depression</td>
      <td>-1</td>
      <td>25</td>
      <td>1013</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Amy</td>
      <td>1975</td>
      <td>6</td>
      <td>27</td>
      <td>12</td>
      <td>29.5</td>
      <td>-79.0</td>
      <td>tropical depression</td>
      <td>-1</td>
      <td>25</td>
      <td>1013</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>Amy</td>
      <td>1975</td>
      <td>6</td>
      <td>28</td>
      <td>18</td>
      <td>34.0</td>
      <td>-77.0</td>
      <td>tropical depression</td>
      <td>-1</td>
      <td>30</td>
      <td>1006</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>Amy</td>
      <td>1975</td>
      <td>6</td>
      <td>29</td>
      <td>0</td>
      <td>34.4</td>
      <td>-75.8</td>
      <td>tropical storm</td>
      <td>0</td>
      <td>35</td>
      <td>1004</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>Amy</td>
      <td>1975</td>
      <td>6</td>
      <td>29</td>
      <td>6</td>
      <td>34.0</td>
      <td>-74.8</td>
      <td>tropical storm</td>
      <td>0</td>
      <td>40</td>
      <td>1002</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 14 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="extracting-data-using-apis">
<h2><span class="section-number">5.3. </span>Extracting data using APIs<a class="headerlink" href="#extracting-data-using-apis" title="Permalink to this headline">¶</a></h2>
<p>Using an API (application programming interface) is another way to draw down information from the interweb. Their just a way for one tool, say Python, to speak to another tool, say a server, and usefully exchange information. The classic use case would be to post a request for data that fits a certain query via an API and to get a download of that data back in return. (You should always preferentially use an API over webscraping a site.)</p>
<p>Because they are designed to work with any tool, you don’t actually need a programming language to interact with an API, it’s just a <em>lot</em> easier if you do.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>An API key is needed in order to access some APIs. Sometimes all you need to do is register with site, in other cases you may have to pay for access.</p>
</div>
<p>To see this, let’s directly use an API to get some time series data. We will make the call out to the internet using the <strong>requests</strong> package.</p>
<p>An API has an ‘endpoint’, the base url, and then a URL that encodes the question. Let’s see an example with the ONS API for which the endpoint is “<a class="reference external" href="https://api.ons.gov.uk/">https://api.ons.gov.uk/</a>”. The rest of the API has the form ‘key/value’, for example we’ll ask for timeseries data ‘timeseries’ followed by ‘JP9Z’ for the vacancies in the UK services sector. We then ask for ‘dataset’ followed by ‘UNEM’ to specify which overarching dataset the series we want is in. The last part asks for the data with ‘data’. Often you won’t need to know all of these details, but it’s useful to see a detailed example.</p>
<p>The data that are returned by APIs are typically in JSON format, which looks a lot like a nested Python dictionary and its entries can be accessed in the same way–this is what is happening when getting the series’ title in the example below. JSON is not good for analysis, so we’ll use <strong>pandas</strong> to put the data into shape.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data&#39;</span>

<span class="c1"># Get the data from the ONS API:</span>
<span class="n">json_data</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

<span class="c1"># Prep the data for a quick plot</span>
<span class="n">title</span> <span class="o">=</span> <span class="n">json_data</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">][</span><span class="s1">&#39;title&#39;</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">json_normalize</span><span class="p">(</span><span class="n">json_data</span><span class="p">[</span><span class="s1">&#39;months&#39;</span><span class="p">]))</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">date</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]),</span>
                <span class="n">value</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]))</span>
        <span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">))</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mf">3.</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/data-extraction_7_0.png" src="_images/data-extraction_7_0.png" />
</div>
</div>
<p>We’ve talked about <em>reading</em> APIs. You can also create your own to serve up data, models, whatever you like! This is an advanced topic and we won’t cover it; but if you do need to, the simplest way is to use <a class="reference external" href="https://fastapi.tiangolo.com/">Fast API</a>. You can find some short video tutorials for Fast API <a class="reference external" href="https://calmcode.io/fastapi/hello-world.html">here</a>.</p>
<div class="section" id="an-easier-way-to-interact-with-some-apis">
<h3><span class="section-number">5.3.1. </span>An easier way to interact with (some) APIs<a class="headerlink" href="#an-easier-way-to-interact-with-some-apis" title="Permalink to this headline">¶</a></h3>
<p>Although it didn’t take much code to get the ONS data, it would be even better if it was just a single line, wouldn’t it? Fortunately there are some packages out there that make this easy, but it does depend on the API (and APIs come and go over time).</p>
<p>By far the most comprehensive library for accessing extra APIs is <a class="reference external" href="https://pandas-datareader.readthedocs.io/en/latest/"><strong>pandas-datareader</strong></a>, which provides convenient access to:</p>
<ul class="simple">
<li><p>FRED</p></li>
<li><p>Quandl</p></li>
<li><p>World Bank</p></li>
<li><p>OECD</p></li>
<li><p>Eurostat</p></li>
</ul>
<p>and more.</p>
<p>Let’s see an example using FRED (the Federal Reserve Bank of St. Louis’ economic data library). This time, let’s look at the UK unemployment rate:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas_datareader.data</span> <span class="k">as</span> <span class="nn">web</span>

<span class="n">df_u</span> <span class="o">=</span> <span class="n">web</span><span class="o">.</span><span class="n">DataReader</span><span class="p">(</span><span class="s1">&#39;LRHUTTTTGBM156S&#39;</span><span class="p">,</span> <span class="s1">&#39;fred&#39;</span><span class="p">)</span>

<span class="n">df_u</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;UK unemployment (percent)&#39;</span><span class="p">,</span>
          <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
          <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
          <span class="n">lw</span><span class="o">=</span><span class="mf">3.</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/data-extraction_9_0.png" src="_images/data-extraction_9_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="webscraping">
<h2><span class="section-number">5.4. </span>Webscraping<a class="headerlink" href="#webscraping" title="Permalink to this headline">¶</a></h2>
<p>Webscraping is a way of grabbing information from the internet that was intended to be displayed in a browser. But it should only be used as a last resort, and only then when permitted by the terms and conditions of a website.</p>
<p>If you’re getting data from the internet, it’s much better to use an API whenever you can: grabbing information in a structure way is <em>exactly</em> why APIs exist. APIs should also be more stable than websites, which may change frequently. Typically, if an organisation is happy for you to grab their data, they will have made an API expressly for that purpose. I’d say it’s pretty rare that there’s a major website which <em>does</em> permit webscraping but which doesn’t have an API; for these websites, if they don’t have an API, chances scraping is against their terms and conditions. Those terms and conditions may be enforceable by law (different rules in different countries here, and you really need legal advice if it’s not unambiguous as to whether you can scrape or not.)</p>
<p>There are other reasons why webscraping is not so good; for example, if you need a back-run then it might be offered through an API but not shown on the webpage. (Or it might not be available at all, in which case it’s best to get in touch with the organisation or check out WaybackMachine in case they took snapshots).</p>
<p>So I’m pretty down on webscraping as there’s almost always a better solution. However, there are occasionally times when it is useful.</p>
<p>If you do find yourself in a scraping situation, be really sure to check that’s legally allowed and also that you are not violating the website’s <code class="docutils literal notranslate"><span class="pre">robots.txt</span></code> rules: this is a special file on almost every website that sets out what’s fair play to crawl (conditional on legality) and what robots should not go poking around in.</p>
<p>In Python, you are spoiled for choice when it comes to webscraping. There are five very strong libraries that cover a real range of user styles and needs: <strong>requests</strong>, <strong>lxml</strong>, <strong>beautifulsoup</strong>, <strong>selenium</strong>, and <em>scrapy</em>*.</p>
<p>For quick and simple webscraping, my usual combo would <strong>requests</strong>, which does little more than go and grab the HTML of a webpage, and <strong>beautifulsoup</strong>, which then helps you to navigate the structure of the page and pull out what you’re actually interested in. For dynamic webpages that use javascript rather than just HTML, you’ll need <strong>selenium</strong>. To scale up and hit thousands of webpages in an efficient way, you might try <strong>scrapy</strong>, which can work with the other tools and handle multiple sessions, and all other kinds of bells and whistles… it’s actually a “web scraping framework”.</p>
<p>It’s always helpful to see coding in practice, so that’s what we’ll do now, but note that we’ll be skipping over a lot of important detail such as user agents, being ‘polite’ with your scraping requests, being efficient with caching and crawling.</p>
<p>In lieu of a better example, let’s scrape <a class="reference external" href="http://aeturrell.com/">http://aeturrell.com/</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://aeturrell.com/&quot;</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n\n&lt;head&gt;\n&lt;script&gt;\n  (function(i,s,o,g,r,a,m){i[\&#39;GoogleAnalyticsObject\&#39;]=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(win&#39;
</pre></div>
</div>
</div>
</div>
<p>Okay, what just happened? We asked requests to grab the HTML of the webpage and then printed the first 300 characters of the text that it found.</p>
<p>Let’s now parse this into something humans can read (or can read more easily) using beautifulsoup:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">prettify</span><span class="p">()[</span><span class="mi">500</span><span class="p">:</span><span class="mi">1000</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>t=&quot;IE=edge&quot; http-equiv=&quot;X-UA-Compatible&quot;/&gt;
  &lt;meta content=&quot;width=device-width, initial-scale=1&quot; name=&quot;viewport&quot;/&gt;
  &lt;meta content=&quot;&quot; name=&quot;description&quot;/&gt;
  &lt;meta content=&quot;&quot; name=&quot;author&quot;/&gt;
  &lt;title&gt;
   Dr Arthur Turrell - website
  &lt;/title&gt;
  &lt;!-- Bootstrap Core CSS --&gt;
  &lt;link href=&quot;css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt;
  &lt;!-- Custom Fonts --&gt;
  &lt;link href=&quot;http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800
</pre></div>
</div>
</div>
</div>
<p>Now we see more structure of the page and even some <em>HTML tags</em> such as ‘title’ and ‘link’. Now we come to the data extraction part: say we want to pull out every paragraph of text, we can use beautifulsoup to skim down the HTML structure and pull out only those parts with the paragraph tag (‘p’).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get all paragraphs</span>
<span class="n">all_paras</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
<span class="c1"># Just show one of the paras</span>
<span class="n">all_paras</span><span class="p">[</span><span class="mi">52</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;p class=&quot;card-text&quot;&gt;This is an example repository for a research project. git clone the project and use it as a skeleton for your own research project. A full explanation may be found in &lt;a href=&quot;http://aeturrell.com//2019/06/26/get-organised/&quot;&gt; this accompanying blog post&lt;/a&gt;.&lt;/p&gt;
</pre></div>
</div>
</div>
</div>
<p>To make this more readable, you can use the <code class="docutils literal notranslate"><span class="pre">.text</span></code> method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">all_paras</span><span class="p">[</span><span class="mi">52</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;This is an example repository for a research project. git clone the project and use it as a skeleton for your own research project. A full explanation may be found in  this accompanying blog post.&#39;
</pre></div>
</div>
</div>
</div>
<p>Now let’s say we didn’t care about most of the page, we <em>only</em> wanted to get hold of the names of projects. For this we need to identify the tag type of the element we’re interested in, in this case ‘div’, and it’s class type, in this case “project-name”. We do it like this (and show nice text in the process):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">projects</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;project-name&#39;</span><span class="p">)</span>
<span class="n">projects</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">projects</span><span class="p">]</span>
<span class="n">projects</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Temperature equilibration in degenerate plasmas&#39;,
 &#39;Large-angle Coulomb collisions in plasmas&#39;,
 &#39;Ultrafast collisional ion heating by electrostatic shocks&#39;,
 &#39;Collisional energy transfer terms in plasmas&#39;,
 &#39;Agent-based dynamics in corporate bond trading&#39;,
 &#39;Making text count: economic forecasting using newspaper text&#39;,
 &#39;Interdisciplinary approaches to macroeconomics&#39;,
 &#39;Transforming naturally occurring text data into economic statistics&#39;,
 &#39;Using machine learning to create bottom-up job classifications&#39;,
 &#39;Pay Transparency and Cracks in the Glass Ceiling&#39;,
 &#39;Solving Heterogeneous General Equilibrium Economic Models with Deep Reinforcement Learning&#39;]
</pre></div>
</div>
</div>
</div>
<p>Hooray! We managed to get the information we wanted: all we needed to know was the right tags. A good tip for finding the tags of the info you want is to look at in your browser (eg Google Chrome) and then right-click on the bit you’re interested in, then hit ‘Inspect’. This will show you the HTML element of the bit of the page you clicked on.</p>
<p>That’s almost it for this very, very brief introduction to webscraping. We’ll just see one more thing: how to iterate over multiple pages.</p>
<p>Imagine we had a root webpage such as “<a class="reference external" href="http://www.codingforeconomists.com">www.codingforeconomists.com</a>” which had subpages such as “<a class="reference external" href="http://www.codingforeconomists.com/page=1">www.codingforeconomists.com/page=1</a>”, “<a class="reference external" href="http://www.codingforeconomists.com/page=2">www.codingforeconomists.com/page=2</a>”, and so on. One need only iterate create the HTML strings to pass into a function that scrapes each one and return the relevant data, eg for the first 50 pages, and with a function called <code class="docutils literal notranslate"><span class="pre">scraper</span></code>, one might run</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">50</span>
<span class="n">root_url</span> <span class="o">=</span> <span class="s2">&quot;www.codingforeconomists.com/page=&quot;</span>
<span class="n">info_on_pages</span> <span class="o">=</span> <span class="p">[</span><span class="n">scraper</span><span class="p">(</span><span class="n">root_url</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)]</span>
</pre></div>
</div>
<p>That’s all we’ll cover here but remember we’ve barely <em>scraped</em> the surface of this big, complex topic. If you want to read about an application, it’s hard not to recommend the paper on webscraping that has undoubtedly change the world the most, and very likely has affected your own life in numerous ways: <a class="reference external" href="http://ilpubs.stanford.edu:8090/422/">“The PageRank Citation Ranking: Bringing Order to the Web”</a> by Page, Brin, Motwani and Winograd. For a more in-depth example of webscraping, check out realpython’s <a class="reference external" href="https://realpython.com/python-web-scraping-practical-introduction/">tutorial</a>.</p>
</div>
<div class="section" id="extracting-data-from-pdfs">
<h2><span class="section-number">5.5. </span>Extracting data from PDFs<a class="headerlink" href="#extracting-data-from-pdfs" title="Permalink to this headline">¶</a></h2>
<p>PDFs are great. Unfortunately, some people love them so much that they think they’re an appropriate way to store data rather than a convenient way to share text and/or figures. Or perhaps there’s a table in a PDF that you’d legitimately like to get the info out from.</p>
<div class="section" id="extracting-images-and-text-from-pdfs">
<h3><span class="section-number">5.5.1. </span>Extracting images and text from PDFs<a class="headerlink" href="#extracting-images-and-text-from-pdfs" title="Permalink to this headline">¶</a></h3>
<p>We’ll use <span class="xref myst"><strong>pdfminer.six</strong></span> to get text out of the same PDF. For this simple operation, it’s just a single command:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">pdfminer.high_level</span> <span class="kn">import</span> <span class="n">extract_text</span>

<span class="c1"># Download the pdf_with_table.pdf file from</span>
<span class="c1"># https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf</span>
<span class="c1"># and put it in a subfolder called data before running the next line</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">extract_text</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;data/pdf_with_table.pdf&#39;</span><span class="p">))</span>

<span class="c1"># Show only first 200 characters of text:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">[:</span><span class="mi">200</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2  Quantifying Fuel-Saving Opportunities from Specific Driving 

Behavior Changes 

2.1  Savings from Improving Individual Driving Profiles 

2.1.1  Drive Profile Subsample from Real-World Travel Surv
</pre></div>
</div>
</div>
</div>
<p>This uses the ‘high-level’ part of the library, which is designed to help cover the most common use cases. But there’s a lot more flexibility there if you need it: essentially, <strong>pdfminer</strong> will break up a pdf into a series of elements that you can sift through in the much the same way as <strong>beautifulsoup</strong> does for HTML. For example, you can use library to <a class="reference external" href="https://pdfminersix.readthedocs.io/en/latest/howto/images.html">extract images</a> from PDFs too.</p>
</div>
<div class="section" id="tables">
<h3><span class="section-number">5.5.2. </span>Tables<a class="headerlink" href="#tables" title="Permalink to this headline">¶</a></h3>
<p>The single best solution to grab tables is probably <a class="reference external" href="https://camelot-py.readthedocs.io/en/master/index.html"><strong>camelot</strong></a>. Note that it does need you to have Ghostscript installed on your computer; you can find more information about the dependencies <a class="reference external" href="https://camelot-py.readthedocs.io/en/master/user/install.html">here</a>. It only works with text-based PDFs and not scanned documents: basically, if you can click and drag to select text in your table in a PDF viewer, then your PDF is text-based. In that case, <strong>camelot</strong> is able to sift through the contents and grab any tables and then pass them back as csvs or even <strong>pandas</strong> dataframes.</p>
<p>At the time of writing, <strong>camelot</strong> had some versioning issues related to a dependency on an outdated version of <strong>sqlalchemy</strong>. You may need to install it in a separate virtual environment to use it.</p>
<p>Here’s a small example that assumes you have a pdf with a table in stored in a local directory:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">camelot</span>
<span class="c1"># Grab the pdf</span>
<span class="n">tables</span> <span class="o">=</span> <span class="n">camelot</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf_with_table.pdf&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>To extract any of the <span class="math notranslate nohighlight">\(n\)</span> tables that are retrieved into a pandas dataframe individually, use <code class="docutils literal notranslate"><span class="pre">tables[0].df</span></code>.</p>
<p>Note that <strong>camelot</strong> is not perfect–so it can produce a report on how it did when it tried to extract each table, which includes an accuracy score. This is found using, for example, <code class="docutils literal notranslate"><span class="pre">tables[0].parsing_report</span></code>.</p>
</div>
<div class="section" id="other-useful-pdf-packages">
<h3><span class="section-number">5.5.3. </span>Other useful PDF packages<a class="headerlink" href="#other-useful-pdf-packages" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://github.com/hoffmangroup/pdfcomments"><strong>pdfcomments</strong></a> is a library that allows you to strip out comments and sticky notes from PDF. This need not strictly be about data extraction, but <a class="reference external" href="https://pythonhosted.org/PyPDF2/"><strong>PyPDF2</strong></a> allows you to both split a PDF into separate pages and merge multiple PDFs together; see <a class="reference external" href="http://www.blog.pythonlibrary.org/2018/04/11/splitting-and-merging-pdfs-with-python/">here</a> for the steps. (You can drag and drop pages using preview on MacOS but this library may be the easiest way to do the same thing on Windows.)</p>
</div>
</div>
<div class="section" id="text-extraction">
<h2><span class="section-number">5.6. </span>Text extraction<a class="headerlink" href="#text-extraction" title="Permalink to this headline">¶</a></h2>
<p>Not everything is a PDF file! If you want to get the text out of .doc, .docx, .epub, .gif, .json, .jpg, <em>.mp3</em>, .odt, .pptx, .rtf, .xlsx, .xls and, actually, .pdf too, then <strong>textract</strong> is for you. Mostly, it’s a wrapper around a ton of other libraries. The upside is that getting the text out should be as easy as calling</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">textract</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">textract</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;path/to/file.extension&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>The downside is that it requires that some other (non-Python) libraries be installed and it doesn’t (yet) work on Windows.</p>
</div>
<div class="section" id="review">
<h2><span class="section-number">5.7. </span>Review<a class="headerlink" href="#review" title="Permalink to this headline">¶</a></h2>
<p>If you know how to get data from:</p>
<ul class="simple">
<li><p>✅ the internet using a URL;</p></li>
<li><p>✅ the internet using an API;</p></li>
<li><p>✅ the internet using webscraping; and</p></li>
<li><p>✅ PDFs, Microsoft Word Documents, and more, using tools like <strong>pdfminer.six</strong> and <strong>textract</strong></p></li>
</ul>
<p>then you have a good basic set of tools for getting the data that you need into a form you can use.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "codeforecon"
        },
        kernelOptions: {
            kernelName: "codeforecon",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'codeforecon'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="data-read-and-write.html" title="previous page"><span class="section-number">4. </span>Reading and Writing Files</a>
    <a class='right-next' id="next-link" href="data-sharing.html" title="next page"><span class="section-number">6. </span>Sharing Data</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Arthur Turrell<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            This book is available under an MIT license.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-189705534-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>